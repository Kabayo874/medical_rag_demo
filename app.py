import streamlit as st
import requests
from openai import OpenAI
import os
import csv
from datetime import datetime

# APIã‚­ãƒ¼ï¼ˆSecretsã‹ã‚‰å–å¾—ï¼‰
GOOGLE_API_KEY = os.environ["GOOGLE_API_KEY"]
CX = os.environ["GOOGLE_CX"]
OPENAI_API_KEY = os.environ["OPENAI_API_KEY"]

client = OpenAI(api_key=OPENAI_API_KEY)
LOG_FILE = "logs.csv"

# --- Googleæ¤œç´¢ ---
def search_whitelist(query, top_k=3):
    url = "https://www.googleapis.com/customsearch/v1"
    params = {"key": GOOGLE_API_KEY, "cx": CX, "q": query}
    res = requests.get(url, params=params).json()
    return res.get("items", [])[:top_k]

# --- ãƒ­ã‚°ä¿å­˜ ---
def save_log(query, conclusion, reason, caution, sources, full_answer):
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    with open(LOG_FILE, mode="a", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow([timestamp, query, conclusion, reason, caution, "; ".join(sources), full_answer])

# --- å›ç­”ç”Ÿæˆ ---
def answer_with_sources(query):
    results = search_whitelist(query)
    if not results:
        return "æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚", "", "", "", []

    snippets = "\n".join(
        [f"[{i+1}] {item['title']} - {item['snippet']} (URL: {item['link']})"
         for i, item in enumerate(results)]
    )

    prompt = f"""
è³ªå•: {query}

ä»¥ä¸‹ã®æ¤œç´¢çµæœã‚’ã‚‚ã¨ã«ã€å¿…ãšæ¬¡ã®å½¢å¼ã§æ—¥æœ¬èªã§ç­”ãˆã¦ãã ã•ã„ã€‚
- çµè«–ï¼š
- æ ¹æ‹ ï¼šï¼ˆçŸ­ã„å¼•ç”¨ï¼‹è„šæ³¨ç•ªå·ï¼‰
- æ³¨æ„ç‚¹ï¼š
- å‡ºå…¸ï¼šï¼ˆç•ªå·ä»˜ãã§URLä¸€è¦§ï¼‰

æ¤œç´¢çµæœ:
{snippets}
"""

    completion = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
    )

    answer = completion.choices[0].message.content

    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã”ã¨ã«åˆ†å‰²
    conclusion, reason, caution, sources = "", "", "", []
    for line in answer.splitlines():
        if line.startswith("- çµè«–ï¼š"):
            conclusion = line.replace("- çµè«–ï¼š", "").strip()
        elif line.startswith("- æ ¹æ‹ ï¼š"):
            reason = line.replace("- æ ¹æ‹ ï¼š", "").strip()
        elif line.startswith("- æ³¨æ„ç‚¹ï¼š"):
            caution = line.replace("- æ³¨æ„ç‚¹ï¼š", "").strip()
        elif line.startswith("- å‡ºå…¸ï¼š"):
            pass
        elif line.strip().startswith("http"):
            sources.append(line.strip())

    # ãƒ­ã‚°ä¿å­˜
    save_log(query, conclusion, reason, caution, sources, answer)

    return answer, conclusion, reason, caution, sources


# --- UIéƒ¨åˆ† ---
st.title("åŒ»ç™‚æƒ…å ±RAG PoC")
st.warning("âš ï¸ æœ¬ãƒ„ãƒ¼ãƒ«ã¯æƒ…å ±æºã‚’çµã‚Šè¾¼ã‚€ã“ã¨ã§ãƒãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’äºˆé˜²ã—æ­£ç¢ºæ€§ã®é«˜ã„æƒ…å ±åé›†ãŒã§ãã¾ã™ã€‚ãŸã ã—ã€å¿…ãšã—ã‚‚æ­£ç¢ºã¨ã¯é™ã‚‰ãªã„ãŸã‚ã€åŒ»ç™‚æƒ…å ±ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã«ã¯å¿…ãšæƒ…å ±æºã®ç¢ºèªã‚’ã—ã¾ã—ã‚‡ã†ã€‚")

query = st.text_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹: 2å‹ç³–å°¿ç—…ã®é™åœ§ç›®æ¨™ã¯ï¼Ÿï¼‰")

if query:
    with st.spinner("æ¤œç´¢ä¸­..."):
        answer, conclusion, reason, caution, sources = answer_with_sources(query)

        st.subheader("ğŸ“Œ å›ç­”")
        st.markdown(answer)

        st.subheader("ğŸ“‚ ãƒ­ã‚°ï¼ˆCSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ï¼‰")
        with open(LOG_FILE, "r", encoding="utf-8") as f:
            st.download_button(
                label="ãƒ­ã‚°ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=f,
                file_name="logs.csv",
                mime="text/csv"
            )
